# AG-UI Request Flow Architecture

This document explains what happens when you type a question in the CopilotKit sidebar and how it flows through the system to your AI agent.

## ğŸ”„ Request Flow: "What's the weather in Paris?"

### Step 1: React Frontend (Port 5173)

```
User types: "What's the weather in Paris?"
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CopilotKit React Component             â”‚
â”‚  <CopilotKit runtimeUrl="/api/copilotkit" agent="agui_assistant">
â”‚                                         â”‚
â”‚  - Captures your message                â”‚
â”‚  - Sends POST to /api/copilotkit        â”‚
â”‚  - agent="agui_assistant" tells it      â”‚
â”‚    which backend agent to use           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
    HTTP POST to /api/copilotkit
    (Vite proxy forwards to port 3001)
```

**File:** `frontend/src/App.tsx`
```tsx
<CopilotKit runtimeUrl="/api/copilotkit" agent="agui_assistant">
```

The Vite dev server proxies `/api/copilotkit` â†’ `http://127.0.0.1:3001` (see `vite.config.ts`).

---

### Step 2: CopilotKit Runtime Server (Port 3001)

```
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Node.js Express Server                 â”‚
â”‚  @copilotkit/runtime                    â”‚
â”‚                                         â”‚
â”‚  - Receives POST /api/copilotkit        â”‚
â”‚  - Looks up agent "agui_assistant"      â”‚
â”‚  - Finds: HttpAgent({ url: 8888 })      â”‚
â”‚  - Forwards request via AG-UI protocol  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
    HTTP POST to http://127.0.0.1:8888/
    (AG-UI protocol with SSE streaming)
```

**File:** `runtime/src/server.ts`
```typescript
const runtime = new CopilotRuntime({
  agents: {
    agui_assistant: new HttpAgent({ url: "http://127.0.0.1:8888/" }),
  },
});
```

The `HttpAgent` from `@ag-ui/client` knows how to speak the **AG-UI protocol** - it sends messages and expects Server-Sent Events (SSE) back.

---

### Step 3: Python AG-UI Server (Port 8888)

```
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FastAPI + Agent Framework              â”‚
â”‚                                         â”‚
â”‚  1. Receives AG-UI formatted request    â”‚
â”‚  2. Passes to ChatAgent                 â”‚
â”‚  3. Agent calls Azure OpenAI            â”‚
â”‚  4. LLM decides to use get_weather tool â”‚
â”‚  5. Tool executes: get_weather("Paris") â”‚
â”‚  6. Result sent back to LLM             â”‚
â”‚  7. LLM generates final response        â”‚
â”‚  8. Streams tokens via SSE              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
    SSE Stream: data: {"type":"TEXT_MESSAGE_CONTENT","delta":"The"}
                data: {"type":"TEXT_MESSAGE_CONTENT","delta":" weather"}
                ...
```

**File:** `server.py`
```python
# The endpoint that receives AG-UI requests
add_agent_framework_fastapi_endpoint(app, agent, "/")

# The agent with tools
agent = ChatAgent(
    name="AGUIAssistant",
    chat_client=chat_client,  # â†’ Azure OpenAI
    tools=[get_weather, get_current_time, calculate],
)
```

---

### Step 4: Azure OpenAI (Cloud)

```
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Azure OpenAI GPT-4o-mini               â”‚
â”‚                                         â”‚
â”‚  Input: User message + tool definitions â”‚
â”‚                                         â”‚
â”‚  LLM thinks: "User wants weather,       â”‚
â”‚  I should call get_weather tool"        â”‚
â”‚                                         â”‚
â”‚  Output: Tool call request              â”‚
â”‚  â†’ {"tool": "get_weather",              â”‚
â”‚     "args": {"location": "Paris"}}      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
    Back to Python server
```

---

### Step 5: Tool Execution (Python Server)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  @ai_function decorator                 â”‚
â”‚                                         â”‚
â”‚  def get_weather(location: str):        â”‚
â”‚      # Simulated weather                â”‚
â”‚      return "Weather in Paris: 22Â°C,    â”‚
â”‚              partly cloudy"             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
    Tool result sent back to Azure OpenAI
         â†“
    LLM generates natural language response
         â†“
    "The weather in Paris is 22Â°C and partly cloudy!"
```

---

### Step 6: Response Streams Back

```
Python Server (8888)
    â†“ SSE events
CopilotKit Runtime (3001)  
    â†“ SSE events
React Frontend (5173)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CopilotSidebar Component               â”‚
â”‚                                         â”‚
â”‚  Receives streaming tokens:             â”‚
â”‚  "The" â†’ "The weather" â†’ "The weather   â”‚
â”‚  in Paris" â†’ ... â†’ complete message     â”‚
â”‚                                         â”‚
â”‚  Renders in real-time! âœ¨               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š Visual Summary

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  React   â”‚â”€â”€â”€â–¶â”‚ CopilotKitâ”‚â”€â”€â”€â–¶â”‚  Python  â”‚â”€â”€â”€â–¶â”‚  Azure   â”‚
â”‚ Frontend â”‚    â”‚  Runtime â”‚    â”‚  AG-UI   â”‚    â”‚  OpenAI  â”‚
â”‚  :5173   â”‚â—€â”€â”€â”€â”‚  :3001   â”‚â—€â”€â”€â”€â”‚  :8888   â”‚â—€â”€â”€â”€â”‚  Cloud   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     UI          Middleware       Agent          LLM
                 (bridges         (tools,        (thinks,
                  protocols)      streaming)     decides)
```

---

## ğŸ”‘ Key Concepts

| Component | Role | Protocol |
|-----------|------|----------|
| **CopilotKit React** | UI, captures user input | Internal |
| **CopilotKit Runtime** | Routes to correct agent | CopilotKit â†’ AG-UI |
| **HttpAgent** | Speaks AG-UI protocol | AG-UI (HTTP + SSE) |
| **FastAPI + Agent Framework** | Hosts agent, executes tools | AG-UI events |
| **ChatAgent** | Orchestrates LLM + tools | Azure OpenAI API |

---

## ğŸ”Œ The AG-UI Protocol

The **AG-UI protocol** is the key - it standardizes how frontends talk to AI agents with:

- **HTTP POST** for sending messages
- **Server-Sent Events (SSE)** for streaming responses
- **Standard event types** like:
  - `RUN_STARTED` - Agent started processing
  - `TEXT_MESSAGE_CONTENT` - Streaming text tokens
  - `TOOL_CALL_START` - Agent is calling a tool
  - `TOOL_CALL_END` - Tool finished executing
  - `RUN_FINISHED` - Agent completed

This standardization means you can swap out:
- The frontend (CopilotKit, custom React, mobile app)
- The agent framework (Microsoft Agent Framework, LangGraph, CrewAI)
- The LLM provider (Azure OpenAI, OpenAI, Anthropic, local models)

...and they'll all work together as long as they speak AG-UI!
